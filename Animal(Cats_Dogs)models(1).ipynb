{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQW7T4TlQAgL",
        "outputId": "ec4289bf-d764-4604-f325-23b0282776a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsnM6H-a5_5x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e7c506-4826-42af-bc2e-8e2eb07a5c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/gdrive/My Drive/Colab Notebooks/image_classification\n"
          ]
        }
      ],
      "source": [
        "cd /gdrive/My Drive/Colab Notebooks/image_classification/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "na1Pm0ywQEns",
        "outputId": "785391f2-dab1-4d99-d28b-3ebbcb6eeea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mahotas\n",
            "  Downloading mahotas-1.4.13-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (5.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7 MB 13.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mahotas) (1.21.6)\n",
            "Installing collected packages: mahotas\n",
            "Successfully installed mahotas-1.4.13\n"
          ]
        }
      ],
      "source": [
        "pip install mahotas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1OCl73WQJ_f"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "import mahotas\n",
        "import cv2\n",
        "import os\n",
        "import h5py\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TtoM7pqQaEo"
      },
      "outputs": [],
      "source": [
        "# make a fix file size\n",
        "fixed_size  = tuple((500,500))\n",
        "\n",
        "#train path \n",
        "train_path = \"dataset/train\"\n",
        "\n",
        "# no of trees for Random Forests\n",
        "num_tree = 100\n",
        "\n",
        "# bins for histograms \n",
        "bins = 8\n",
        "\n",
        "# train_test_split size\n",
        "test_size = 0.10\n",
        "\n",
        "# seed for reproducing same result \n",
        "seed = 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsFS9rxCQc8N"
      },
      "outputs": [],
      "source": [
        "# features description -1:  Hu Moments\n",
        "\n",
        "def fd_hu_moments(image):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
        "    return feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsDI62WbQhKC"
      },
      "outputs": [],
      "source": [
        "# feature-descriptor -2 Haralick Texture \n",
        "\n",
        "def fd_haralick(image):\n",
        "    # conver the image to grayscale\n",
        "    gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "    # Ccompute the haralick texture fetature ve tor \n",
        "    haralic = mahotas.features.haralick(gray).mean(axis=0)\n",
        "    return haralic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_F4OPlk_QmaU"
      },
      "outputs": [],
      "source": [
        "# feature-description -3 Color Histogram\n",
        "\n",
        "def fd_histogram(image, mask=None):\n",
        "    # conver the image to HSV colors-space\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    #COPUTE THE COLOR HISTPGRAM\n",
        "    hist  = cv2.calcHist([image],[0,1,2],None,[bins,bins,bins], [0, 256, 0, 256, 0, 256])\n",
        "    # normalize the histogram\n",
        "    cv2.normalize(hist,hist)\n",
        "    # return the histog....\n",
        "    return hist.flatten()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUGdOpzPQpP9",
        "outputId": "8e3d82b3-77dd-4a1e-c115-e6becfb96dd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cats', 'dogs']\n"
          ]
        }
      ],
      "source": [
        "# get the training data labels \n",
        "train_labels = os.listdir(train_path)\n",
        "\n",
        "# sort the training labesl \n",
        "train_labels.sort()\n",
        "print(train_labels)\n",
        "\n",
        "# empty list to hold feature vectors and labels \n",
        "global_features = []\n",
        "labels = []\n",
        "\n",
        "i, j = 0, 0 \n",
        "k = 0\n",
        "\n",
        "# num of images per class \n",
        "images_per_class = 80"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBZG6NhuZExU",
        "outputId": "63c0a8b8-4e09-4363-ea17-01b54f5e198f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 4.05 µs\n",
            "[STATUS] processed folder: cats\n",
            "[STATUS] processed folder: dogs\n",
            "[STATUS] completed Global Feature Extraction...\n"
          ]
        }
      ],
      "source": [
        "# ittirate the folder to get the image label name\n",
        "\n",
        "%time\n",
        "# lop over the training data sub folder \n",
        "\n",
        "for training_name in train_labels:\n",
        "    # join the training data path and each species training folder\n",
        "    dir = os.path.join(train_path, training_name)\n",
        "\n",
        "    # get the current training label\n",
        "    current_label = training_name\n",
        "\n",
        "    k = 1\n",
        "    # loop over the images in each sub-folder\n",
        "        \n",
        "    for file in os.listdir(dir):\n",
        "\n",
        "        file = dir + \"/\" + os.fsdecode(file)\n",
        "       \n",
        "        # read the image and resize it to a fixed-size\n",
        "        image = cv2.imread(file) \n",
        "        \n",
        "        if image is not None:\n",
        "            image = cv2.resize(image,fixed_size)\n",
        "            fv_hu_moments = fd_hu_moments(image)\n",
        "            fv_haralick   = fd_haralick(image)\n",
        "            fv_histogram  = fd_histogram(image)\n",
        "        #else:\n",
        "            #print(\"image not loaded\")\n",
        "                \n",
        "        #image = cv2.imread(file)        \n",
        "        #image = cv2.resize(image,fixed_size)\n",
        "\n",
        "        # Concatenate global features\n",
        "        global_feature = np.hstack([fv_histogram, fv_haralick, fv_hu_moments])\n",
        "\n",
        "        # update the list of labels and feature vectors\n",
        "        labels.append(current_label)\n",
        "        global_features.append(global_feature)\n",
        "\n",
        "        i += 1\n",
        "        k += 1\n",
        "    print(\"[STATUS] processed folder: {}\".format(current_label))\n",
        "    j += 1\n",
        "\n",
        "print(\"[STATUS] completed Global Feature Extraction...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_mmKq91wZRsy",
        "outputId": "ea7b1400-5c24-4675-b180-83defcb5ba30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5 µs, sys: 3 µs, total: 8 µs\n",
            "Wall time: 39.3 µs\n",
            "[STATUS] feature vector size (8017, 532)\n",
            "[STATUS] training Labels (8017,)\n",
            "[STATUS] training labels encoded...{}\n",
            "[STATUS] feature vector normalized...\n",
            "[STATUS] target labels: [0 0 0 ... 1 1 1]\n",
            "[STATUS] target labels shape: (8017,)\n",
            "[STATUS] end of training..\n"
          ]
        }
      ],
      "source": [
        "%time\n",
        "import h5py\n",
        "# get the overall feature vector size\n",
        "print(\"[STATUS] feature vector size {}\".format(np.array(global_features).shape))\n",
        "\n",
        "# get the overall training label size\n",
        "print(\"[STATUS] training Labels {}\".format(np.array(labels).shape))\n",
        "\n",
        "# encode the target labels\n",
        "targetNames = np.unique(labels)\n",
        "le = LabelEncoder()\n",
        "target = le.fit_transform(labels)\n",
        "print(\"[STATUS] training labels encoded...{}\")\n",
        "# normalize the feature vector in the range (0-1)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaled_features = scaler.fit_transform(global_features)\n",
        "print(\"[STATUS] feature vector normalized...\")\n",
        "\n",
        "print(\"[STATUS] target labels: {}\".format(target))\n",
        "print(\"[STATUS] target labels shape: {}\".format(target.shape))\n",
        "\n",
        "# save the feature vector using HDF5\n",
        "h5f_data = h5py.File('output/data.h5', 'w')\n",
        "h5f_data.create_dataset('dataset_1', data=np.array(rescaled_features))\n",
        "\n",
        "h5f_label = h5py.File('output/labels.h5', 'w')\n",
        "h5f_label.create_dataset('dataset_1', data=np.array(target))\n",
        "\n",
        "h5f_data.close()\n",
        "h5f_label.close()\n",
        "\n",
        "print(\"[STATUS] end of training..\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nW0cg26EabT_"
      },
      "outputs": [],
      "source": [
        "# import the feature vector and trained labels\n",
        "\n",
        "h5f_data = h5py.File('output/data.h5', 'r')\n",
        "h5f_label = h5py.File('output/labels.h5', 'r')\n",
        "\n",
        "global_features_string = h5f_data['dataset_1']\n",
        "global_labels_string = h5f_label['dataset_1']\n",
        "\n",
        "global_features = np.array(global_features_string)\n",
        "global_labels = np.array(global_labels_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VjFdricao1L"
      },
      "outputs": [],
      "source": [
        "# split the training and testing data\n",
        "(trainDataGlobal, testDataGlobal, trainLabelsGlobal, testLabelsGlobal) = train_test_split(np.array(global_features),\n",
        "                                                                                          np.array(global_labels),\n",
        "                                                                                          test_size=test_size,\n",
        "                                                                                          random_state=seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z52z3hDeasvh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "492e1584-2578-4172-8fc2-71c7c2116692"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3621\n",
            "           1       1.00      1.00      1.00      3594\n",
            "\n",
            "    accuracy                           1.00      7215\n",
            "   macro avg       1.00      1.00      1.00      7215\n",
            "weighted avg       1.00      1.00      1.00      7215\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "# create the model - Random Forests\n",
        "clf  = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# fit the training data to the model\n",
        "clf.fit(trainDataGlobal, trainLabelsGlobal)\n",
        "\n",
        "#print(clf.fit(trainDataGlobal, trainLabelsGlobal))\n",
        "\n",
        "clf_pred = clf.predict(trainDataGlobal)\n",
        "#clf_pred = clf.predict(global_feature.reshape(1,-1))[0]\n",
        "print(classification_report(trainLabelsGlobal,clf_pred))\n",
        "#print(confusion_matrix(trainLabelsGlobal,clf_pred))\n",
        "\n",
        "#print(clf.predict(trainDataGlobal))\n",
        "\n",
        "#print(clf.predict(global_feature.reshape(1,-1))[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQRbG9qdoGAN"
      },
      "outputs": [],
      "source": [
        "# path to test data\n",
        "test_path = \"dataset/test\"\n",
        "\n",
        "# loop through the test images\n",
        "#for file in glob.glob(test_path + \"/*.jpg\"):\n",
        "for file in os.listdir(test_path):    \n",
        "\n",
        "    file = test_path + \"/\" + file\n",
        "    #print(file)\n",
        "    \n",
        "    # read the image\n",
        "    image = cv2.imread(file)\n",
        "\n",
        "    # resize the image\n",
        "    image = cv2.resize(image, fixed_size)\n",
        "\n",
        "    # Global Feature extraction\n",
        "    fv_hu_moments = fd_hu_moments(image)\n",
        "    fv_haralick   = fd_haralick(image)\n",
        "    fv_histogram  = fd_histogram(image)\n",
        "\n",
        "    # Concatenate global features\n",
        "\n",
        "    global_feature = np.hstack([fv_histogram, fv_haralick, fv_hu_moments])\n",
        "\n",
        "    # predict label of test image\n",
        "    prediction = clf.predict(global_feature.reshape(1,-1))[0]\n",
        "\n",
        "    # show predicted label on image\n",
        "    cv2.putText(image, train_labels[prediction], (20,30), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0,255,255), 3)\n",
        "\n",
        "    # display the output image\n",
        "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Animal(Cats_Dogs)models.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}